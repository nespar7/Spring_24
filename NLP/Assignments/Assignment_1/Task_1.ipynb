{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install contextualSpellCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import spacy\n",
    "import contextualSpellCheck\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "contextualSpellCheck.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    return doc._.performed_spellCheck, doc._.outcome_spellCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spellings(csv_file, column_name, should_log=False):\n",
    "    # read a csv file, in each line, see if spellCheck was performed(if text was correctly spelled) and print original and corrected texts\n",
    "    lines = []\n",
    "\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lines = list(reader)\n",
    "\n",
    "        # Index of the column to be spell checked\n",
    "        column_index = lines[0].index(column_name)\n",
    "\n",
    "        # For each line, perform spell check\n",
    "        for i in range(1, len(lines)):\n",
    "            line = lines[i][column_index]\n",
    "\n",
    "            performed, outcome = spell_check(line)\n",
    "\n",
    "            # If spell check was performed, update the line and print the original and corrected texts\n",
    "            if should_log and performed:\n",
    "                print(line)\n",
    "                print(outcome)\n",
    "                print()\n",
    "            \n",
    "            # Update the line\n",
    "            lines[i][column_index] = outcome\n",
    "\n",
    "    # Write the spell checked lines to a new csv file named \"spell_checked + csv_file\" in the same directory\n",
    "\n",
    "    # get csv file directory\n",
    "    csv_file_dir = csv_file.split('/')\n",
    "\n",
    "    # get csv file name\n",
    "    csv_file_name = csv_file_dir[-1]\n",
    "\n",
    "    # add spell_checked to the csv file name\n",
    "    csv_file_name = \"spell_checked_\" + csv_file_name\n",
    "\n",
    "    # get csv file directory\n",
    "    csv_file_dir = csv_file_dir[:-1]\n",
    "\n",
    "    # join the directory and the file name for the final path\n",
    "    spell_checked_csv_file_path = '/'.join(csv_file_dir) + '/' + csv_file_name \n",
    "    \n",
    "    with open(spell_checked_csv_file_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "    print(\"Spell check completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(csv_file, column_name):\n",
    "    # read a csv file, in each line, remove characters apart from alphanumerics and whitespaces in the given column\n",
    "    lines = []\n",
    "\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lines = list(reader)\n",
    "\n",
    "        # Index of the column to be pre processed\n",
    "        column_index = lines[0].index(column_name)\n",
    "\n",
    "        for i in range(1, len(lines)):\n",
    "            lines[i][column_index] = ''.join([c for c in lines[i][column_index] if c.isalnum() or c.isspace()])\n",
    "\n",
    "    # write the pre-processed data to a new csv file named \"pre_processed + csv_file\" in the same directory\n",
    "\n",
    "    # get csv file directory\n",
    "    csv_file_dir = csv_file.split('/')\n",
    "\n",
    "    # get csv file name\n",
    "    csv_file_name = csv_file_dir[-1]\n",
    "\n",
    "    # add \"pre_processed\" to the csv file name\n",
    "    pre_processed_csv_file_name = \"pre_processed_\" + csv_file_name\n",
    "\n",
    "    # get csv file directory\n",
    "    csv_file_dir = csv_file_dir[:-1]\n",
    "\n",
    "    # get the final path of the resulting csv file\n",
    "    pre_processed_csv_file_path = '/'.join(csv_file_dir) + '/' + pre_processed_csv_file_name\n",
    "\n",
    "    # write the pre-processed data to the resulting csv file\n",
    "    with open(pre_processed_csv_file_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "    print(\"Pre procesing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing the CSV files for docs and queries.\n",
    "\n",
    "The CSV file locations need to be changed as applicable if being run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_file = \"/content/Query_Doc/docs.csv\"\n",
    "queries_file = \"/content/Query_Doc/queries.csv\"\n",
    "\n",
    "pre_process(docs_file, \"doc_text\")\n",
    "pre_process(queries_file, \"query_text\")\n",
    "\n",
    "pre_processed_docs_file = \"/content/Query_Doc/pre_processed_docs.csv\"\n",
    "pre_processed_queries_file = \"/content/Query_Doc/pre_processed_queries.csv\"\n",
    "\n",
    "correct_spellings(pre_processed_docs_file, \"doc_text\")\n",
    "correct_spellings(pre_processed_queries_file, \"query_text\", True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
